{
    "docs": [
        {
            "location": "/",
            "text": "asterius\n is a Haskell to WebAssembly compiler. The project is in alpha stage and in active development.\n\n\nSponsors\n\n\nAsterius is maintained by \nTweag I/O\n.\n\n\nHave questions? Need help? Tweet at \n@tweagio\n.",
            "title": "Home"
        },
        {
            "location": "/#sponsors",
            "text": "Asterius is maintained by  Tweag I/O .  Have questions? Need help? Tweet at  @tweagio .",
            "title": "Sponsors"
        },
        {
            "location": "/building/",
            "text": "Building guide\n\n\nasterius\n is tested on Linux x64 and Windows x64. macOS x64 may also work. A pre-built Docker image is provided.\n\n\nUsing a pre-built Docker image\n\n\nWe build and test Docker images on CircleCI. They are pushed to \nterrorjack/asterius\n, the tags are git revisions. \nterrorjack/asterius:latest\n correspond to latest revision on \nmaster\n.\n\n\nPut input program in a directory (e.g. \n~/mirror\n), then map the directory to a Docker volume:\n\n\nterrorjack@ubuntu:~$ docker run -it -v ~/mirror:/mirror terrorjack/asterius\nroot@76bcb511663d:~# cd /mirror\nroot@76bcb511663d:/mirror# ahc-link --help\n...\n\n\n\n\nBuilding custom \nghc\n\n\nasterius\n requires a forked \nghc\n which can be found \nhere\n. We are looking forward to building \nasterius\n with vanilla \nghc-head\n in the long run, but at the moment, we use our own \nghc\n fork so it's easy to test radical changes on \nghc\n itself.\n\n\nThe building guide of \nghc\n can be found \nhere\n.\n\n\nOn Linux/Windows, a prebuilt \nghc\n tarball is provided. It's already included in \nstack.yaml\n. Note that the Windows bindist does not provide prof libs/haddock (due to AppVeyor build time restriction).\n\n\nExtra dependencies\n\n\nBesides the custom \nghc\n, these dependencies are also required:\n\n\n\n\ncmake\n/\nmake\n/\ng++\n: For building in-tree \nbinaryen\n\n\nautoconf\n: For booting \nghc-prim\n/\nbase\n\n\nnodejs\n: For running tests. Ensure the latest version is used, since we rely on some recent V8 experimental features (e.g. BigInt support)\n\n\nstack\n: Someday \ncabal\n may also work, no specific obstacles anyway.\n\n\n\n\nBuilding \nasterius\n\n\nstack build asterius\n. That's it. Set \nMAKEFLAGS=-j8\n to pass flags to \nmake\n for parallel building of \nbinaryen\n.\n\n\nAfter the dust settles, run \nstack exec ahc-boot\n to perform booting. Set the \nASTERIUS_DEBUG\n environment variable to make \nahc-boot\n print IRs to text files which are useful when debugging compiled code of standard libraries. Be aware that this flag slows down the booting process significantly!",
            "title": "Building guide"
        },
        {
            "location": "/building/#building-guide",
            "text": "asterius  is tested on Linux x64 and Windows x64. macOS x64 may also work. A pre-built Docker image is provided.",
            "title": "Building guide"
        },
        {
            "location": "/building/#using-a-pre-built-docker-image",
            "text": "We build and test Docker images on CircleCI. They are pushed to  terrorjack/asterius , the tags are git revisions.  terrorjack/asterius:latest  correspond to latest revision on  master .  Put input program in a directory (e.g.  ~/mirror ), then map the directory to a Docker volume:  terrorjack@ubuntu:~$ docker run -it -v ~/mirror:/mirror terrorjack/asterius\nroot@76bcb511663d:~# cd /mirror\nroot@76bcb511663d:/mirror# ahc-link --help\n...",
            "title": "Using a pre-built Docker image"
        },
        {
            "location": "/building/#building-custom-ghc",
            "text": "asterius  requires a forked  ghc  which can be found  here . We are looking forward to building  asterius  with vanilla  ghc-head  in the long run, but at the moment, we use our own  ghc  fork so it's easy to test radical changes on  ghc  itself.  The building guide of  ghc  can be found  here .  On Linux/Windows, a prebuilt  ghc  tarball is provided. It's already included in  stack.yaml . Note that the Windows bindist does not provide prof libs/haddock (due to AppVeyor build time restriction).",
            "title": "Building custom ghc"
        },
        {
            "location": "/building/#extra-dependencies",
            "text": "Besides the custom  ghc , these dependencies are also required:   cmake / make / g++ : For building in-tree  binaryen  autoconf : For booting  ghc-prim / base  nodejs : For running tests. Ensure the latest version is used, since we rely on some recent V8 experimental features (e.g. BigInt support)  stack : Someday  cabal  may also work, no specific obstacles anyway.",
            "title": "Extra dependencies"
        },
        {
            "location": "/building/#building-asterius",
            "text": "stack build asterius . That's it. Set  MAKEFLAGS=-j8  to pass flags to  make  for parallel building of  binaryen .  After the dust settles, run  stack exec ahc-boot  to perform booting. Set the  ASTERIUS_DEBUG  environment variable to make  ahc-boot  print IRs to text files which are useful when debugging compiled code of standard libraries. Be aware that this flag slows down the booting process significantly!",
            "title": "Building asterius"
        },
        {
            "location": "/ahc-link/",
            "text": "Using \nahc-link\n\n\nahc-link\n is the frontend program of asterius compiler. It reads Haskell modules as inputs and generates one \n.wasm\n WebAssembly binary file and one \n.js\n stub loader script, which can be run in a Node.js or Chrome runtime.\n\n\nThe help text of \nahc-link\n is pasted here for your convenience:\n\n\nahc-link - Linker for the Asterius compiler\n\nUsage: ahc-link [--browser] --input ARG [--output-wasm ARG] [--output-js ARG]\n                [--output-html ARG] [--output-link-report ARG]\n                [--output-graphviz ARG] [--binaryen] [--debug] [--output-ir]\n                [--run] [--heap-size ARG] [--asterius-instance-callback ARG]\n                [--ghc-option ARG] [--export-function ARG]\n                [--extra-root-symbol ARG]\n  Producing a standalone WebAssembly binary from Haskell\n\nAvailable options:\n  --browser                Target browsers instead of Node.js\n  --input ARG              Path of the Main module\n  --output-wasm ARG        Output path of WebAssembly binary, defaults to same\n                           path of Main\n  --output-js ARG          Output path of JavaScript, defaults to same path of\n                           Main. Must be the same directory as the WebAssembly\n                           binary.\n  --output-html ARG        Output path of HTML, defaults to same path of Main.\n                           Must be the same directory as the WebAssembly binary.\n  --output-link-report ARG Output path of linking report\n  --output-graphviz ARG    Output path of GraphViz file of symbol dependencies\n  --binaryen               Use the binaryen backend\n  --debug                  Enable debug mode in the runtime\n  --output-ir              Output Asterius IR of compiled modules\n  --run                    Run the compiled module with Node.js\n  --heap-size ARG          Heap size in MBs, used for both nursery/object pool.\n                           Defaults to 1024.\n  --asterius-instance-callback ARG\n                           Supply a JavaScript callback expression which will be\n                           invoked on the initiated asterius instance. Defaults\n                           to calling Main.main\n  --ghc-option ARG         Extra GHC flags\n  --export-function ARG    Symbol of exported function\n  --extra-root-symbol ARG  Symbol of extra root entity, e.g. Main_f_closure\n  -h,--help                Show this help text",
            "title": "Using ahc-link"
        },
        {
            "location": "/ahc-link/#using-ahc-link",
            "text": "ahc-link  is the frontend program of asterius compiler. It reads Haskell modules as inputs and generates one  .wasm  WebAssembly binary file and one  .js  stub loader script, which can be run in a Node.js or Chrome runtime.  The help text of  ahc-link  is pasted here for your convenience:  ahc-link - Linker for the Asterius compiler\n\nUsage: ahc-link [--browser] --input ARG [--output-wasm ARG] [--output-js ARG]\n                [--output-html ARG] [--output-link-report ARG]\n                [--output-graphviz ARG] [--binaryen] [--debug] [--output-ir]\n                [--run] [--heap-size ARG] [--asterius-instance-callback ARG]\n                [--ghc-option ARG] [--export-function ARG]\n                [--extra-root-symbol ARG]\n  Producing a standalone WebAssembly binary from Haskell\n\nAvailable options:\n  --browser                Target browsers instead of Node.js\n  --input ARG              Path of the Main module\n  --output-wasm ARG        Output path of WebAssembly binary, defaults to same\n                           path of Main\n  --output-js ARG          Output path of JavaScript, defaults to same path of\n                           Main. Must be the same directory as the WebAssembly\n                           binary.\n  --output-html ARG        Output path of HTML, defaults to same path of Main.\n                           Must be the same directory as the WebAssembly binary.\n  --output-link-report ARG Output path of linking report\n  --output-graphviz ARG    Output path of GraphViz file of symbol dependencies\n  --binaryen               Use the binaryen backend\n  --debug                  Enable debug mode in the runtime\n  --output-ir              Output Asterius IR of compiled modules\n  --run                    Run the compiled module with Node.js\n  --heap-size ARG          Heap size in MBs, used for both nursery/object pool.\n                           Defaults to 1024.\n  --asterius-instance-callback ARG\n                           Supply a JavaScript callback expression which will be\n                           invoked on the initiated asterius instance. Defaults\n                           to calling Main.main\n  --ghc-option ARG         Extra GHC flags\n  --export-function ARG    Symbol of exported function\n  --extra-root-symbol ARG  Symbol of extra root entity, e.g. Main_f_closure\n  -h,--help                Show this help text",
            "title": "Using ahc-link"
        },
        {
            "location": "/jsffi/",
            "text": "JavaScript FFI\n\n\nThere is a prototype implementation of \nforeign import javascript\n right now, check the \njsffi\n test suite for details. The syntax is like:\n\n\nforeign import javascript \"new Date()\" current_time :: IO JSRef\n\nforeign import javascript \"console.log(${1})\" js_print :: JSRef -> IO ()\n\n\n\n\nThe source text of \nforeign import javascript\n should be a valid JavaScript expression (but you can use something like \n${1}\n, \n${2}\n to refer to the function parameters). Supported basic types are:\n\n\n\n\nPtr\n\n\nFunPtr\n\n\nStablePtr\n\n\nBool\n\n\nInt\n\n\nWord\n\n\nChar\n\n\nFloat\n\n\nDouble\n\n\nJSRef\n\n\n\n\nThe result can be wrapped in \nIO\n (or not).\n\n\nJSRef\n is a magic type that doesn't actually appear in any module's source code. In the Haskell land, \nJSRef\n is first-class and opaque: you can pass it around, put it in a data structure, etc, but under the hood it's just a handle. The runtime maintains mappings from handles to real JavaScript objects.\n\n\nNote that it's currently impossible to properly define \nnewtype\ns to \nJSRef\n and use them in JSFFI import/export declarations. The asterius compiler rewrites all \nJSRef\n to \nInt\n at parse time, which doesn't play well with the ordinary FFI type checking mechanism. We need to stay with type synonyms at the moment.\n\n\nAlso, a prototype of \nforeign export javascript\n is implemented, check \njsffi\n for details. The syntax is roughly:\n\n\nforeign export javascript \"mult_hs\" (*) :: Int -> Int -> Int\n\n\n\n\nIn a Haskell module, one can specify the exported function name (must be globally unique), along with its Haskell identifier and type. One can specify \nahc-link --export-function=mult_hs\n to make the linker include the relevant bits in final WebAssembly binary, and export \nmult_hs\n as a regular WebAssembly export function. After calling \nhs_init\n to initialize the runtime, one can call \nmult_hs\n just like a regular JavaScript function.\n\n\nAdding a JSFFI basic type\n\n\nLook at the following places:\n\n\n\n\nAsterius.JSFFI\n module. All JavaScript reference types are uniformly handled as \nFFI_JSREF\n, while value types are treated as \nFFI_VAL\n. Assuming we are adding a value type. Add logic to:\n\n\nmarshalToFFIValueType\n: Recognize the value type in parsed AST, and translate to \nFFI_VAL\n\n\n\n\n\n\nAsterius.Builtins\n module. Add the corresponding \nrts_mkXX\n/\nrts_getXX\n builtin functions. They are required for stub functions of \nforeign export javascript\n.\n\n\n\n\nImplementation\n\n\nThis subsection presents a high-level overview on the implementation of JSFFI, based on the information flow from syntactic sugar to generated WebAssembly/JavaScript code.\n\n\nSyntactic sugar\n\n\nAs documented in previous sections, one can write \nforeign import javascript\n or \nforeign export javascript\n clauses in a \n.hs\n module. How are they processed? The logic resides in \nAsterius.JSFFI\n.\n\n\nFirst, there is \naddFFIProcessor\n, which given a \nCompiler\n (defined in \nghc-toolkit\n), returns a new \nCompiler\n and a callback to fetch a stub module. The details of \nCompiler\n's implementation are not relevant here, just think of it as an abstraction layer to fetch/modify GHC IRs without dealing with all the details of GHC API.\n\n\naddFFIProcessor\n adds one functionality to the input \nCompiler\n: rewrite parsed Haskell AST and handle the \nforeign import javascript\n/\nforeign export javascript\n syntactic sugar. After rewriting, JavaScript FFI is really turned into C FFI, so type-checking/code generation proceeds as normal.\n\n\nAfter the parsed AST is processed, a \"stub module\" of type \nAsteriusModule\n is generated and can be later fetched given an \nAsteriusModuleSymbol\n. It contains JSFFI related information of type \nFFIMarshalState\n. Both \nAsteriusModule\n and \nFFIMarshalState\n types has \nSemigroup\n instance so they can be combined later at link-time.\n\n\nTODO",
            "title": "JavaScript FFI"
        },
        {
            "location": "/jsffi/#javascript-ffi",
            "text": "There is a prototype implementation of  foreign import javascript  right now, check the  jsffi  test suite for details. The syntax is like:  foreign import javascript \"new Date()\" current_time :: IO JSRef\n\nforeign import javascript \"console.log(${1})\" js_print :: JSRef -> IO ()  The source text of  foreign import javascript  should be a valid JavaScript expression (but you can use something like  ${1} ,  ${2}  to refer to the function parameters). Supported basic types are:   Ptr  FunPtr  StablePtr  Bool  Int  Word  Char  Float  Double  JSRef   The result can be wrapped in  IO  (or not).  JSRef  is a magic type that doesn't actually appear in any module's source code. In the Haskell land,  JSRef  is first-class and opaque: you can pass it around, put it in a data structure, etc, but under the hood it's just a handle. The runtime maintains mappings from handles to real JavaScript objects.  Note that it's currently impossible to properly define  newtype s to  JSRef  and use them in JSFFI import/export declarations. The asterius compiler rewrites all  JSRef  to  Int  at parse time, which doesn't play well with the ordinary FFI type checking mechanism. We need to stay with type synonyms at the moment.  Also, a prototype of  foreign export javascript  is implemented, check  jsffi  for details. The syntax is roughly:  foreign export javascript \"mult_hs\" (*) :: Int -> Int -> Int  In a Haskell module, one can specify the exported function name (must be globally unique), along with its Haskell identifier and type. One can specify  ahc-link --export-function=mult_hs  to make the linker include the relevant bits in final WebAssembly binary, and export  mult_hs  as a regular WebAssembly export function. After calling  hs_init  to initialize the runtime, one can call  mult_hs  just like a regular JavaScript function.",
            "title": "JavaScript FFI"
        },
        {
            "location": "/jsffi/#adding-a-jsffi-basic-type",
            "text": "Look at the following places:   Asterius.JSFFI  module. All JavaScript reference types are uniformly handled as  FFI_JSREF , while value types are treated as  FFI_VAL . Assuming we are adding a value type. Add logic to:  marshalToFFIValueType : Recognize the value type in parsed AST, and translate to  FFI_VAL    Asterius.Builtins  module. Add the corresponding  rts_mkXX / rts_getXX  builtin functions. They are required for stub functions of  foreign export javascript .",
            "title": "Adding a JSFFI basic type"
        },
        {
            "location": "/jsffi/#implementation",
            "text": "This subsection presents a high-level overview on the implementation of JSFFI, based on the information flow from syntactic sugar to generated WebAssembly/JavaScript code.",
            "title": "Implementation"
        },
        {
            "location": "/jsffi/#syntactic-sugar",
            "text": "As documented in previous sections, one can write  foreign import javascript  or  foreign export javascript  clauses in a  .hs  module. How are they processed? The logic resides in  Asterius.JSFFI .  First, there is  addFFIProcessor , which given a  Compiler  (defined in  ghc-toolkit ), returns a new  Compiler  and a callback to fetch a stub module. The details of  Compiler 's implementation are not relevant here, just think of it as an abstraction layer to fetch/modify GHC IRs without dealing with all the details of GHC API.  addFFIProcessor  adds one functionality to the input  Compiler : rewrite parsed Haskell AST and handle the  foreign import javascript / foreign export javascript  syntactic sugar. After rewriting, JavaScript FFI is really turned into C FFI, so type-checking/code generation proceeds as normal.  After the parsed AST is processed, a \"stub module\" of type  AsteriusModule  is generated and can be later fetched given an  AsteriusModuleSymbol . It contains JSFFI related information of type  FFIMarshalState . Both  AsteriusModule  and  FFIMarshalState  types has  Semigroup  instance so they can be combined later at link-time.",
            "title": "Syntactic sugar"
        },
        {
            "location": "/jsffi/#todo",
            "text": "",
            "title": "TODO"
        },
        {
            "location": "/rts-api/",
            "text": "Invoking RTS API in JavaScript\n\n\nFor the brave souls who prefer to play with raw pointers instead of syntactic sugar, it's possible to invoke RTS API directly in JavaScript. This grants us the ability to:\n\n\n\n\nAllocate memory, create and inspect Haskell closures on the heap.\n\n\nTrigger Haskell evaluation, then retrieve the results back into JavaScript.\n\n\nUse raw Cmm symbols to summon any function, not limited to the \"foreign exported\" ones.\n\n\n\n\nHere is a simple example. Suppose we have a \nMain.fact\n function:\n\n\nfact :: Int -> Int\nfact 0 = 1\nfact n = n * fact (n - 1)\n\n\n\n\nThe first step is ensuring \nfact\n is actually contained in the final WebAssembly binary produced by \nahc-link\n. \nahc-link\n performs aggressive dead-code elimination (or more precisely, live-code discovery) by starting from a set of \"root symbols\" (usually \nMain_main_closure\n which corresponds to \nMain.main\n), repeatedly traversing ASTs and including any discovered symbols. So if \nMain.main\n does not have a transitive dependency on \nfact\n, \nfact\n won't be included into the binary. In order to include \nfact\n, either use it in some way in \nmain\n, or supply \n--extra-root-symbol=Main_fact_closure\n flag to \nahc-link\n when compiling.\n\n\nThe next step is locating the pointer of \nfact\n. The \"asterius instance\" type we mentioned before contains two \"symbol map\" fields: \nstaticsSymbolMap\n maps static data symbols to linear memory absolute addresses, and \nfunctionSymbolMap\n maps function symbols to WebAssembly function table indices. In this case, we can use \ni.staticsSymbolMap.Main_fact_closure\n as the pointer value of \nMain_fact_closure\n. For a Haskell top-level function, there're also pointers to the info table/entry function, but we don't need those two in this example.\n\n\nSince we'd like to call \nfact\n, we need to apply it to an argument, build a thunk representing the result, then evaluate the thunk to WHNF and retrieve the result. Assuming we're passing \n--asterius-instance-callback=i=>{ ... }\n to \nahc-link\n, in the callback body, we can use RTS API like this:\n\n\ni.wasmInstance.exports.hs_init();\nconst cap = i.staticsSymbolMap.MainCapability;\nconst argument = i.wasmInstance.exports.rts_mkInt(cap, 5);\nconst thunk = i.wasmInstance.exports.rts_apply(cap, i.staticsSymbolMap.Main_fact_closure, argument);\nconst ret = i.wasmInstance.exports.allocate(cap, 1);\ni.wasmInstance.exports.rts_eval(cap, thunk, ret);\nconsole.log(i.wasmInstance.exports.rts_getInt(i.wasmInstance.exports.loadI64(ret)));\n\n\n\n\nA line-by-line explanation follows:\n\n\n\n\nAs usual, the first step is calling \nhs_init\n to initialize the runtime.\n\n\nMost RTS API functions requires passing a \nCapability\n as the first argument, which can be thought as a single processor core for the virtual machine executing Haskell code. Since asterius only has a non-threaded runtime at the moment, we can simply use \nMainCapability\n as the pointer to the unique global \nCapability\n.\n\n\nAssuming we'd like to calculate \nfact 5\n, we need to build an \nInt\n object which value is \n5\n. We can't directly pass the JavaScript \n5\n, instead we should call \nrts_mkInt\n, which properly allocates a heap object and sets up the info pointer of an \nInt\n value. When we need to pass a value of basic type (e.g. \nInt\n, \nStablePtr\n, etc), we should always call \nrts_mk*\n and use the returned pointers to the allocated heap object.\n\n\nThen we can apply \nfact\n to \n5\n by using \nrts_apply\n. It builds a thunk without triggering evaluation. If we are dealing with a curried multiple-arguments function, we should chain \nrts_apply\n repeatedly until we get a thunk representing the final result.\n\n\nBefore triggering evaluation, we need to allocate one single word, which serves as the \"result pointer\". All the \nrts_eval*\n functions expect a \"result pointer\", and upon successful evaluation, the result (which is yet another heap object)'s pointer will be written to the place pointed by the \"result pointer\". If we don't care about the result (e.g. \nIO ()\n), it's okay to pass \n0\n there.\n\n\nFinally, we call \nrts_eval\n, which enters the runtime and perform all the evaluation for us. There are different types of evaluation functions:\n\n\nrts_eval\n evaluates a thunk of type \na\n to WHNF.\n\n\nrts_evalIO\n evaluates the result of \nIO a\n to WHNF.\n\n\nrts_evalLazyIO\n evaluates \nIO a\n, without forcing the result to WHNF. It is also the default evaluator used by the runtime to run \nMain.main\n.\n\n\nrts_evalStableIO\n evaluates the result of \nStablePtr (IO a)\n to WHNF, then return the result as \nStablePtr a\n.\n\n\nIf we need to retrieve the result back to JavaScript, we must pick an evaluator function which forces the result to WHNF. The \nrts_get*\n functions assume the objects are evaluated and won't trigger evaluation.\n\n\nFinally, we use \nloadI64\n to retrieve the \nInt\n object stored in the space pointed by \nret\n, then use \nrts_getInt\n to retrieve the content of that \nInt\n. The result is the integer value we expect.\n\n\n\n\nMost users probably don't need to use RTS API manually, since the \nforeign import\n/\nexport\n syntactic sugar and the \nmakeHaskellCallback\n interface should be sufficient for typical use cases of Haskell/JavaScript interaction. Though it won't hurt to know what is hidden beneath the syntactic sugar, \nforeign import\n/\nexport\n is implemented by automatically generating stub WebAssembly functions which calls RTS API for you.",
            "title": "Invoking RTS API in JavaScript"
        },
        {
            "location": "/rts-api/#invoking-rts-api-in-javascript",
            "text": "For the brave souls who prefer to play with raw pointers instead of syntactic sugar, it's possible to invoke RTS API directly in JavaScript. This grants us the ability to:   Allocate memory, create and inspect Haskell closures on the heap.  Trigger Haskell evaluation, then retrieve the results back into JavaScript.  Use raw Cmm symbols to summon any function, not limited to the \"foreign exported\" ones.   Here is a simple example. Suppose we have a  Main.fact  function:  fact :: Int -> Int\nfact 0 = 1\nfact n = n * fact (n - 1)  The first step is ensuring  fact  is actually contained in the final WebAssembly binary produced by  ahc-link .  ahc-link  performs aggressive dead-code elimination (or more precisely, live-code discovery) by starting from a set of \"root symbols\" (usually  Main_main_closure  which corresponds to  Main.main ), repeatedly traversing ASTs and including any discovered symbols. So if  Main.main  does not have a transitive dependency on  fact ,  fact  won't be included into the binary. In order to include  fact , either use it in some way in  main , or supply  --extra-root-symbol=Main_fact_closure  flag to  ahc-link  when compiling.  The next step is locating the pointer of  fact . The \"asterius instance\" type we mentioned before contains two \"symbol map\" fields:  staticsSymbolMap  maps static data symbols to linear memory absolute addresses, and  functionSymbolMap  maps function symbols to WebAssembly function table indices. In this case, we can use  i.staticsSymbolMap.Main_fact_closure  as the pointer value of  Main_fact_closure . For a Haskell top-level function, there're also pointers to the info table/entry function, but we don't need those two in this example.  Since we'd like to call  fact , we need to apply it to an argument, build a thunk representing the result, then evaluate the thunk to WHNF and retrieve the result. Assuming we're passing  --asterius-instance-callback=i=>{ ... }  to  ahc-link , in the callback body, we can use RTS API like this:  i.wasmInstance.exports.hs_init();\nconst cap = i.staticsSymbolMap.MainCapability;\nconst argument = i.wasmInstance.exports.rts_mkInt(cap, 5);\nconst thunk = i.wasmInstance.exports.rts_apply(cap, i.staticsSymbolMap.Main_fact_closure, argument);\nconst ret = i.wasmInstance.exports.allocate(cap, 1);\ni.wasmInstance.exports.rts_eval(cap, thunk, ret);\nconsole.log(i.wasmInstance.exports.rts_getInt(i.wasmInstance.exports.loadI64(ret)));  A line-by-line explanation follows:   As usual, the first step is calling  hs_init  to initialize the runtime.  Most RTS API functions requires passing a  Capability  as the first argument, which can be thought as a single processor core for the virtual machine executing Haskell code. Since asterius only has a non-threaded runtime at the moment, we can simply use  MainCapability  as the pointer to the unique global  Capability .  Assuming we'd like to calculate  fact 5 , we need to build an  Int  object which value is  5 . We can't directly pass the JavaScript  5 , instead we should call  rts_mkInt , which properly allocates a heap object and sets up the info pointer of an  Int  value. When we need to pass a value of basic type (e.g.  Int ,  StablePtr , etc), we should always call  rts_mk*  and use the returned pointers to the allocated heap object.  Then we can apply  fact  to  5  by using  rts_apply . It builds a thunk without triggering evaluation. If we are dealing with a curried multiple-arguments function, we should chain  rts_apply  repeatedly until we get a thunk representing the final result.  Before triggering evaluation, we need to allocate one single word, which serves as the \"result pointer\". All the  rts_eval*  functions expect a \"result pointer\", and upon successful evaluation, the result (which is yet another heap object)'s pointer will be written to the place pointed by the \"result pointer\". If we don't care about the result (e.g.  IO () ), it's okay to pass  0  there.  Finally, we call  rts_eval , which enters the runtime and perform all the evaluation for us. There are different types of evaluation functions:  rts_eval  evaluates a thunk of type  a  to WHNF.  rts_evalIO  evaluates the result of  IO a  to WHNF.  rts_evalLazyIO  evaluates  IO a , without forcing the result to WHNF. It is also the default evaluator used by the runtime to run  Main.main .  rts_evalStableIO  evaluates the result of  StablePtr (IO a)  to WHNF, then return the result as  StablePtr a .  If we need to retrieve the result back to JavaScript, we must pick an evaluator function which forces the result to WHNF. The  rts_get*  functions assume the objects are evaluated and won't trigger evaluation.  Finally, we use  loadI64  to retrieve the  Int  object stored in the space pointed by  ret , then use  rts_getInt  to retrieve the content of that  Int . The result is the integer value we expect.   Most users probably don't need to use RTS API manually, since the  foreign import / export  syntactic sugar and the  makeHaskellCallback  interface should be sufficient for typical use cases of Haskell/JavaScript interaction. Though it won't hurt to know what is hidden beneath the syntactic sugar,  foreign import / export  is implemented by automatically generating stub WebAssembly functions which calls RTS API for you.",
            "title": "Invoking RTS API in JavaScript"
        },
        {
            "location": "/ir/",
            "text": "IR types and transformation passes\n\n\nThis section explains various IR types in asterius, and hopefully presents a clear picture of how information flows from Haskell to WebAssembly. (There's a similar section in \njsffi.md\n which explains implementation details of JSFFI)\n\n\nCmm IR\n\n\nEverything starts from Cmm, or more specifically, \"raw\" Cmm which satisfies:\n\n\n\n\nAll calls are tail calls, parameters are passed by global registers like R1 or on the stack.\n\n\nAll info tables are converted to binary data segments.\n\n\n\n\nCheck \nCmm\n module in \nghc\n package to get started on Cmm.\n\n\nAsterius obtains in-memory raw Cmm via:\n\n\n\n\ncmmToRawCmmHook\n in our custom GHC fork. This allow us to lay our fingers on Cmm generated by either compiling Haskell modules, or \n.cmm\n files (which are in \nrts\n)\n\n\nThere is some abstraction in \nghc-toolkit\n, the compiler logic is actually in the \nCompiler\n datatype as some callbacks, and \nghc-toolkit\n converts them to hooks, frontend plugins and \nghc\n executable wrappers.\n\n\n\n\nThere is one minor annoyance with the Cmm types in GHC (or any other GHC IR type): it's very hard to serialize/deserialize them without setting up complicated contexts related to package databases, etc. To experiment with new backends, it's reasonable to marshal to a custom serializable IR first.\n\n\nPre-linking expression IR\n\n\nWe then marshal raw Cmm to an expression IR defined in \nAsterius.Types\n. Each compilation unit (Haskell module or \n.cmm\n file) maps to one \nAsteriusModule\n, and each \nAsteriusModule\n is serialized to a \n.asterius_o\n object file which will be deserialized at link time. Since we serialize/deserialize a structured expression IR faithfully, it's possible to perform aggressive LTO by traversing/rewriting IR at link time, and that's what we're doing right now.\n\n\nThe expression IR is mostly a Haskell modeling of a subset of \nbinaryen\n's expression IR, with some additions:\n\n\n\n\nUnresolved\n related variants, which allow us to use a symbol as an expression. At link time, the symbols are re-written to absolute addresses.\n\n\nUnresolved locals/globals. At link time, unresolved locals are laid out to wasm locals, and unresolved globals (which are really just Cmm global regs) become fields in the global Capability's \nStgRegTable\n.\n\n\nEmitErrorMessage\n, as a placeholder of emitting a string error message then trapping. At link time, such error messages are collected into an \"error message pool\", and the wasm code is just \"calling some error message reporting function with an array index\".\n\n\nNull\n. We're civilized, educated functional programmers and should really be using \nMaybe Expression\n in some fields instead of adding a \nNull\n constructor, but this is just handy. Blame me.\n\n\n\n\nIt's possible to encounter things we can't handle in Cmm (unsupported primops, etc). So \nAsteriusModule\n also contains compile-time error messages when something isn't supported, but the errors are not reported, instead they are deferred to runtime error messages. (Ideally link-time, but it turns out to be hard)\n\n\nThe symbols are simply converted to Z-encoded strings that also contain module prefixes, and they are assumed to be unique across different compilation units.\n\n\nThe store\n\n\nThere's an \nAsteriusStore\n type in \nAsterius.Types\n. It's an immutable data structure that maps symbols to underlying entities in the expression IR for every single module, and is a critical component of the linker.\n\n\nModeling the store as a self-contained data structure makes it pleasant to write linker logic, at the cost of exploding RAM usage. So we implemented a poor man's KV store in \nAsterius.Store\n which performs lazy-loading of modules: when initializing the store, we only load the symbols, but not the actual modules; only when a module is \"requested\" for the first time, we perform deserialization for that module.\n\n\nAsteriusStore\n supports merging. It's a handy operation, since we can first initialize a \"global\" store that represents the standard libraries, then make another store based on compiling user input, simply merge the two and we can start linking from the output store.\n\n\nPost-linking expression IR\n\n\nAt link time, we take \nAsteriusStore\n which contains everything (standard libraries and user input code), then performs live-code discovery: starting from a \"root symbol set\" (something like \nMain_main_closure\n), iteratively fetch the entity from the store, traverse the AST and collect new symbols. When we reach a fixpoint, that fixpoint is the outcome of dependency analysis, representing a self-contained wasm module.\n\n\nWe then do some rewriting work on the self contained module: making symbol tables, rewriting symbols to absolute addresses, using our own relooper to convert from control-flow graphs to structured control flow, etc. Most of the logic is in \nAsterius.Resolve\n.\n\n\nThe output of linker is \nModule\n. It differs from \nAsteriusModule\n, and although it shares quite some datatypes with \nAsteriusModule\n (for example, \nExpression\n), it guarantees that some variants will not appear (for example, \nUnresolved*\n). A \nModule\n is ready to be fed to a backend which emits real wasm binary code.\n\n\nThere are some useful linker byproducts. For example, there's \nLinkReport\n which contains mappings from symbols to addresses which will be lost in wasm binary code, but is still useful for debugging.\n\n\nGenerating binary code via binaryen\n\n\nOnce we have a \nModule\n (which is essentially just Haskell modeling of binaryen C API), we can invoke binaryen to validate it and generate wasm binary code. The low-level bindings are maintained in the \nbinaryen\n package, and \nAsterius.Marshal\n contains the logic to call the imported functions to do actual work.\n\n\nGenerating binary code via wasm-toolkit\n\n\nWe can also convert \nModule\n to IR types of \nwasm-toolkit\n, which is our native Haskell wasm engine. It's now the default backend of \nahc-link\n, but the binaryen backend can still be chosen by \nahc-link --binaryen\n.\n\n\nGenerating JavaScript stub script\n\n\nTo make it actually run in Node.js/Chrome, we need two pieces of JavaScript code:\n\n\n\n\nCommon runtime which can be reused across different asterius compiled modules. It's in \nasterius/rts/rts.js\n.\n\n\nStub code which contains specific information like error messages, etc.\n\n\n\n\nThe linker generates stub script along with wasm binary code, and concats the runtime and the stub script to a self-contained JavaScript file which can be run or embedded. It's possible to specify JavaScript \"target\" to either Node.js or Chrome via \nahc-link\n flags.",
            "title": "IR types and transformation passes"
        },
        {
            "location": "/ir/#ir-types-and-transformation-passes",
            "text": "This section explains various IR types in asterius, and hopefully presents a clear picture of how information flows from Haskell to WebAssembly. (There's a similar section in  jsffi.md  which explains implementation details of JSFFI)",
            "title": "IR types and transformation passes"
        },
        {
            "location": "/ir/#cmm-ir",
            "text": "Everything starts from Cmm, or more specifically, \"raw\" Cmm which satisfies:   All calls are tail calls, parameters are passed by global registers like R1 or on the stack.  All info tables are converted to binary data segments.   Check  Cmm  module in  ghc  package to get started on Cmm.  Asterius obtains in-memory raw Cmm via:   cmmToRawCmmHook  in our custom GHC fork. This allow us to lay our fingers on Cmm generated by either compiling Haskell modules, or  .cmm  files (which are in  rts )  There is some abstraction in  ghc-toolkit , the compiler logic is actually in the  Compiler  datatype as some callbacks, and  ghc-toolkit  converts them to hooks, frontend plugins and  ghc  executable wrappers.   There is one minor annoyance with the Cmm types in GHC (or any other GHC IR type): it's very hard to serialize/deserialize them without setting up complicated contexts related to package databases, etc. To experiment with new backends, it's reasonable to marshal to a custom serializable IR first.",
            "title": "Cmm IR"
        },
        {
            "location": "/ir/#pre-linking-expression-ir",
            "text": "We then marshal raw Cmm to an expression IR defined in  Asterius.Types . Each compilation unit (Haskell module or  .cmm  file) maps to one  AsteriusModule , and each  AsteriusModule  is serialized to a  .asterius_o  object file which will be deserialized at link time. Since we serialize/deserialize a structured expression IR faithfully, it's possible to perform aggressive LTO by traversing/rewriting IR at link time, and that's what we're doing right now.  The expression IR is mostly a Haskell modeling of a subset of  binaryen 's expression IR, with some additions:   Unresolved  related variants, which allow us to use a symbol as an expression. At link time, the symbols are re-written to absolute addresses.  Unresolved locals/globals. At link time, unresolved locals are laid out to wasm locals, and unresolved globals (which are really just Cmm global regs) become fields in the global Capability's  StgRegTable .  EmitErrorMessage , as a placeholder of emitting a string error message then trapping. At link time, such error messages are collected into an \"error message pool\", and the wasm code is just \"calling some error message reporting function with an array index\".  Null . We're civilized, educated functional programmers and should really be using  Maybe Expression  in some fields instead of adding a  Null  constructor, but this is just handy. Blame me.   It's possible to encounter things we can't handle in Cmm (unsupported primops, etc). So  AsteriusModule  also contains compile-time error messages when something isn't supported, but the errors are not reported, instead they are deferred to runtime error messages. (Ideally link-time, but it turns out to be hard)  The symbols are simply converted to Z-encoded strings that also contain module prefixes, and they are assumed to be unique across different compilation units.",
            "title": "Pre-linking expression IR"
        },
        {
            "location": "/ir/#the-store",
            "text": "There's an  AsteriusStore  type in  Asterius.Types . It's an immutable data structure that maps symbols to underlying entities in the expression IR for every single module, and is a critical component of the linker.  Modeling the store as a self-contained data structure makes it pleasant to write linker logic, at the cost of exploding RAM usage. So we implemented a poor man's KV store in  Asterius.Store  which performs lazy-loading of modules: when initializing the store, we only load the symbols, but not the actual modules; only when a module is \"requested\" for the first time, we perform deserialization for that module.  AsteriusStore  supports merging. It's a handy operation, since we can first initialize a \"global\" store that represents the standard libraries, then make another store based on compiling user input, simply merge the two and we can start linking from the output store.",
            "title": "The store"
        },
        {
            "location": "/ir/#post-linking-expression-ir",
            "text": "At link time, we take  AsteriusStore  which contains everything (standard libraries and user input code), then performs live-code discovery: starting from a \"root symbol set\" (something like  Main_main_closure ), iteratively fetch the entity from the store, traverse the AST and collect new symbols. When we reach a fixpoint, that fixpoint is the outcome of dependency analysis, representing a self-contained wasm module.  We then do some rewriting work on the self contained module: making symbol tables, rewriting symbols to absolute addresses, using our own relooper to convert from control-flow graphs to structured control flow, etc. Most of the logic is in  Asterius.Resolve .  The output of linker is  Module . It differs from  AsteriusModule , and although it shares quite some datatypes with  AsteriusModule  (for example,  Expression ), it guarantees that some variants will not appear (for example,  Unresolved* ). A  Module  is ready to be fed to a backend which emits real wasm binary code.  There are some useful linker byproducts. For example, there's  LinkReport  which contains mappings from symbols to addresses which will be lost in wasm binary code, but is still useful for debugging.",
            "title": "Post-linking expression IR"
        },
        {
            "location": "/ir/#generating-binary-code-via-binaryen",
            "text": "Once we have a  Module  (which is essentially just Haskell modeling of binaryen C API), we can invoke binaryen to validate it and generate wasm binary code. The low-level bindings are maintained in the  binaryen  package, and  Asterius.Marshal  contains the logic to call the imported functions to do actual work.",
            "title": "Generating binary code via binaryen"
        },
        {
            "location": "/ir/#generating-binary-code-via-wasm-toolkit",
            "text": "We can also convert  Module  to IR types of  wasm-toolkit , which is our native Haskell wasm engine. It's now the default backend of  ahc-link , but the binaryen backend can still be chosen by  ahc-link --binaryen .",
            "title": "Generating binary code via wasm-toolkit"
        },
        {
            "location": "/ir/#generating-javascript-stub-script",
            "text": "To make it actually run in Node.js/Chrome, we need two pieces of JavaScript code:   Common runtime which can be reused across different asterius compiled modules. It's in  asterius/rts/rts.js .  Stub code which contains specific information like error messages, etc.   The linker generates stub script along with wasm binary code, and concats the runtime and the stub script to a self-contained JavaScript file which can be run or embedded. It's possible to specify JavaScript \"target\" to either Node.js or Chrome via  ahc-link  flags.",
            "title": "Generating JavaScript stub script"
        },
        {
            "location": "/debugging/",
            "text": "The runtime debugging feature\n\n\nThere is a runtime debugging mode which can be enabled by the \n--debug\n flag for \nahc-link\n. When enabled, the compiler inserts \"tracing\" instructions in the following places:\n\n\n\n\nThe start of a function/basic block\n\n\nSetLocal\n when the local type is \nI64\n\n\nMemory load/stores, when the value type is \nI64\n\n\n\n\nThe tracing messages are quite helpful in observing control flow transfers and memory operations. Remember to also use the \n--output-link-report\n flag to dump the linking report, which contains mapping from data/function symbols to addresses.\n\n\nThe runtime debugging mode also enables a \"memory trap\" which intercepts every memory load/store instruction and checks if the address is null pointer or other uninitialized regions of the linear memory. The program immediately aborts if an invalid address is encountered. (When debugging mode is switched off, program continues execution and the rest of control flow is all undefined behavior!)\n\n\nVirtual address spaces\n\n\nRemember that we're compiling to \nwasm32\n which has a 32-bit address space, but the host GHC is actually 64-bits, so all pointers in asterius are 64-bits, and upon \nload\n/\nstore\n/\ncall_indirect\n, we truncate the 64-bit pointer, using only the lower 32-bits for indexing.\n\n\nThe higher 32-bits of pointers are idle tag bits at our disposal, so, we implemented simple virtual address spaces. The linker/runtime is aware of the distinction between:\n\n\n\n\nThe \nphysical\n address, which is either an \ni32\n index of the linear memory for data, or an \ni32\n index of the table for functions.\n\n\nThe \nlogical\n address, which is the \ni64\n pointer value we're passing around.\n\n\n\n\nAll access to the memory/table is achieved by using the \nlogical\n address. The access operations are accompanied by a \nmapping\n operation which translates a \nlogical\n address to a \nphysical\n one. Currently it's just a truncate, but in the future we may get a more feature-complete \nmmap\n/\nmunmap\n implementation, and some additional computation may occur when address translation is done.\n\n\nWe chose two magic numbers (in \nAsterius.Internals.MagicNumber\n) as the tag bits for data/function pointers. The numbers are chosen so that when applied, the \nlogical\n address does not exceed JavaScript's safe integer limit.\n\n\nWhen we emit debug log entries, we may encounter various \ni64\n values. We examine the higher 32-bits, and if it matches the pointer tag bits, we do a lookup in the data/function symbol table, and if there's a hit, we output the symbol along the value. This spares us the pain to keep a lot of symbol/address mappings in our working memory when examining the debug logs. Some false positives (e.g. some random intermediate \ni64\n value in a Haskell computation accidently collides with a \nlogical\n address) may exist in theory, but the probability should be very low.\n\n\nNote that for consistency between vanilla/debug mode, the virtual address spaces are in effect even in vanilla mode. This won't add extra overhead, since the truncate instruction for 64-bit addresses has been present since the beginning.\n\n\nComplete list of emitted debugging log entries\n\n\n\n\nAssertions: some hand-written WebAssembly functions in \nAsterius.Builtins\n contain assertions which are only active in debugging mode. Failure of an assertion causes a string error message to be printed, and the whole execution flow aborted.\n\n\nMemory traps: In \nAsterius.MemoryTrap\n, we implement a rewriting pass which rewrites all load/store instructions into invocations of load/store wrapper functions. The wrapper functions are defined in \nAsterius.Builtins\n, which checks the address and traps if it's an invalid one (null pointer, uninitialized region, etc).\n\n\nControl-flow: In \nAsterius.Tracing\n, we implement a rewriting pass on functions (which are later invoked at link-time in \nAsterius.Resolve\n), which emits messages when:\n\n\nEntering a Cmm function.\n\n\nEntering a basic block. To make sense of block ids, you need to dump pre-linking IRs (which isn't processed by the relooper yet, and preserves the control-flow graph structure)\n\n\nAssigning a value to an i64 local. To make sense of local ids, dump IRs. Also note that the local ids here doesn't match the actual local ids in wasm binary code (there is a re-mapping upon serialization), but it shouldn't be a problem since we are debugging the higher level IR here.\n\n\n\n\n\n\n\n\nDumping IRs\n\n\nThere are multiple ways to dump IRs:\n\n\n\n\nVia GHC flags: GHC flags like \n-ddump-to-file -ddump-cmm-raw\n dump pretty-printed GHC IRs to files.\n\n\nVia environment variable: Set the \nASTERIUS_DEBUG\n environment variable, then during booting, a number of IRs (mainly raw Cmm in its AST form, instead of pretty-printed form) will be dumped.\n\n\nVia \nahc-link\n flag: Use \nahc-link --output-ir\n to dump IRs when compiling user code.",
            "title": "The runtime debugging feature"
        },
        {
            "location": "/debugging/#the-runtime-debugging-feature",
            "text": "There is a runtime debugging mode which can be enabled by the  --debug  flag for  ahc-link . When enabled, the compiler inserts \"tracing\" instructions in the following places:   The start of a function/basic block  SetLocal  when the local type is  I64  Memory load/stores, when the value type is  I64   The tracing messages are quite helpful in observing control flow transfers and memory operations. Remember to also use the  --output-link-report  flag to dump the linking report, which contains mapping from data/function symbols to addresses.  The runtime debugging mode also enables a \"memory trap\" which intercepts every memory load/store instruction and checks if the address is null pointer or other uninitialized regions of the linear memory. The program immediately aborts if an invalid address is encountered. (When debugging mode is switched off, program continues execution and the rest of control flow is all undefined behavior!)",
            "title": "The runtime debugging feature"
        },
        {
            "location": "/debugging/#virtual-address-spaces",
            "text": "Remember that we're compiling to  wasm32  which has a 32-bit address space, but the host GHC is actually 64-bits, so all pointers in asterius are 64-bits, and upon  load / store / call_indirect , we truncate the 64-bit pointer, using only the lower 32-bits for indexing.  The higher 32-bits of pointers are idle tag bits at our disposal, so, we implemented simple virtual address spaces. The linker/runtime is aware of the distinction between:   The  physical  address, which is either an  i32  index of the linear memory for data, or an  i32  index of the table for functions.  The  logical  address, which is the  i64  pointer value we're passing around.   All access to the memory/table is achieved by using the  logical  address. The access operations are accompanied by a  mapping  operation which translates a  logical  address to a  physical  one. Currently it's just a truncate, but in the future we may get a more feature-complete  mmap / munmap  implementation, and some additional computation may occur when address translation is done.  We chose two magic numbers (in  Asterius.Internals.MagicNumber ) as the tag bits for data/function pointers. The numbers are chosen so that when applied, the  logical  address does not exceed JavaScript's safe integer limit.  When we emit debug log entries, we may encounter various  i64  values. We examine the higher 32-bits, and if it matches the pointer tag bits, we do a lookup in the data/function symbol table, and if there's a hit, we output the symbol along the value. This spares us the pain to keep a lot of symbol/address mappings in our working memory when examining the debug logs. Some false positives (e.g. some random intermediate  i64  value in a Haskell computation accidently collides with a  logical  address) may exist in theory, but the probability should be very low.  Note that for consistency between vanilla/debug mode, the virtual address spaces are in effect even in vanilla mode. This won't add extra overhead, since the truncate instruction for 64-bit addresses has been present since the beginning.",
            "title": "Virtual address spaces"
        },
        {
            "location": "/debugging/#complete-list-of-emitted-debugging-log-entries",
            "text": "Assertions: some hand-written WebAssembly functions in  Asterius.Builtins  contain assertions which are only active in debugging mode. Failure of an assertion causes a string error message to be printed, and the whole execution flow aborted.  Memory traps: In  Asterius.MemoryTrap , we implement a rewriting pass which rewrites all load/store instructions into invocations of load/store wrapper functions. The wrapper functions are defined in  Asterius.Builtins , which checks the address and traps if it's an invalid one (null pointer, uninitialized region, etc).  Control-flow: In  Asterius.Tracing , we implement a rewriting pass on functions (which are later invoked at link-time in  Asterius.Resolve ), which emits messages when:  Entering a Cmm function.  Entering a basic block. To make sense of block ids, you need to dump pre-linking IRs (which isn't processed by the relooper yet, and preserves the control-flow graph structure)  Assigning a value to an i64 local. To make sense of local ids, dump IRs. Also note that the local ids here doesn't match the actual local ids in wasm binary code (there is a re-mapping upon serialization), but it shouldn't be a problem since we are debugging the higher level IR here.",
            "title": "Complete list of emitted debugging log entries"
        },
        {
            "location": "/debugging/#dumping-irs",
            "text": "There are multiple ways to dump IRs:   Via GHC flags: GHC flags like  -ddump-to-file -ddump-cmm-raw  dump pretty-printed GHC IRs to files.  Via environment variable: Set the  ASTERIUS_DEBUG  environment variable, then during booting, a number of IRs (mainly raw Cmm in its AST form, instead of pretty-printed form) will be dumped.  Via  ahc-link  flag: Use  ahc-link --output-ir  to dump IRs when compiling user code.",
            "title": "Dumping IRs"
        },
        {
            "location": "/architecture/",
            "text": "High-level architecture\n\n\nThe \nasterius\n project is hosted at \nGitHub\n. The monorepo contains several packages:\n\n\n\n\nasterius\n. This is the central package of the \nasterius\n compiler.\n\n\nbinaryen\n. It contains the latest source code of the C++ library \nbinaryen\n in tree, and provides complete raw bindings to its \nC API\n.\n\n\nghc-toolkit\n. It provides a framework for implementing Haskell-to-X compilers by retrieving \nghc\n's various types of in-memory intermediate representations. It also contains the latest source code of \nghc-prim\n/\ninteger-gmp\n/\ninteger-simple\n/\nbase\n in tree.\n\n\nwasm-toolkit\n. It implements the WebAssembly AST and binary encoder/decoder in Haskell, and is now the default backend for generating WebAssembly binary code.\n\n\n\n\nThe \nasterius\n package provides an \nahc\n executable which is a drop-in replacement of \nghc\n to be used with \nSetup configure\n. \nahc\n redirects all arguments to the real \nghc\n most of the time, but when it's invoked with the \n--make\n major mode, it invokes \nghc\n with its frontend plugin. This is inspired by Edward Yang's \nHow to integrate GHC API programs with Cabal\n.\n\n\nBased on \nghc-toolkit\n, \nasterius\n implements a \nghc\n frontend plugin\n which translates \nCmm\n to \nbinaryen\n IR. The serialized \nbinaryen\n IR can then be loaded and linked to a WebAssembly binary (not implemented yet). The normal compilation pipeline which generates native machine code is not affected.\n\n\nAbout \"booting\"\n\n\nIn order for \nasterius\n to support non-trivial Haskell programs (that is, at least most things in \nPrelude\n), it needs to run the compilation process for \nbase\n and its dependent packages. This process is known as \"booting\".\n\n\nThe \nasterius\n package provides an \nahc-boot\n test suite which tests booting by compiling the wired-in packages provided by \nghc-toolkit\n and using \nahc\n to replace \nghc\n when configuring. This is inspired by Joachim Breitner's \nveggies\n.",
            "title": "Project architecture"
        },
        {
            "location": "/architecture/#high-level-architecture",
            "text": "The  asterius  project is hosted at  GitHub . The monorepo contains several packages:   asterius . This is the central package of the  asterius  compiler.  binaryen . It contains the latest source code of the C++ library  binaryen  in tree, and provides complete raw bindings to its  C API .  ghc-toolkit . It provides a framework for implementing Haskell-to-X compilers by retrieving  ghc 's various types of in-memory intermediate representations. It also contains the latest source code of  ghc-prim / integer-gmp / integer-simple / base  in tree.  wasm-toolkit . It implements the WebAssembly AST and binary encoder/decoder in Haskell, and is now the default backend for generating WebAssembly binary code.   The  asterius  package provides an  ahc  executable which is a drop-in replacement of  ghc  to be used with  Setup configure .  ahc  redirects all arguments to the real  ghc  most of the time, but when it's invoked with the  --make  major mode, it invokes  ghc  with its frontend plugin. This is inspired by Edward Yang's  How to integrate GHC API programs with Cabal .  Based on  ghc-toolkit ,  asterius  implements a  ghc  frontend plugin  which translates  Cmm  to  binaryen  IR. The serialized  binaryen  IR can then be loaded and linked to a WebAssembly binary (not implemented yet). The normal compilation pipeline which generates native machine code is not affected.",
            "title": "High-level architecture"
        },
        {
            "location": "/architecture/#about-booting",
            "text": "In order for  asterius  to support non-trivial Haskell programs (that is, at least most things in  Prelude ), it needs to run the compilation process for  base  and its dependent packages. This process is known as \"booting\".  The  asterius  package provides an  ahc-boot  test suite which tests booting by compiling the wired-in packages provided by  ghc-toolkit  and using  ahc  to replace  ghc  when configuring. This is inspired by Joachim Breitner's  veggies .",
            "title": "About \"booting\""
        },
        {
            "location": "/wasm-in-hs/",
            "text": "Writing WebAssembly code in Haskell\n\n\nIn \nAsterius.Builtins\n, there are WebAssembly shims which serve as our runtime. We choose to write WebAssembly code in Haskell, using Haskell as our familiar meta-language.\n\n\nAs of now, there are two ways of writing WebAssembly code in Haskell. The first way is directly manipulating AST types as specified in \nAsterius.Types\n. Those types are pretty bare-metal and maps closely to binaryen IR. Simply write some code to generate an \nAsteriusFunction\n, and ensure the function and its symbol is present in the store when linking starts. It will eventually be bundled into output WebAssembly binary file.\n\n\nDirectly using \nAsterius.Types\n is not a pleasant experience, it's basically a DDoS on one's working memory, since the developer needs to keep a lot of things in mind: parameter/local ids, block/loop labels, etc. Also, the resulting Haskell code is pretty verbose, littered with syntactic noise (e.g. tons of list concats when constructing a block)\n\n\nWe now provide an EDSL in \nAsterius.EDSL\n to construct an \nAsteriusFunction\n. Its core type is \nEDSL a\n, and can be composed with a \nMonad\n or \nMonoid\n interface. Most builtin functions in \nAsterius.Builtins\n are already refactored to use this EDSL. Typical usages:\n\n\n\n\n\"Allocate\" a parameter/local. Use \nparam\n or \nlocal\n to obtain an immutable \nExpression\n which corresponds to the value of a new parameter/local. There are also mutable variants.\n\n\nAn opaque \nLVal\n type is provided to uniformly deal with local reads/assignments and memory loads/stores. Once an \nLVal\n is instantiated, it can be used to read an \nExpression\n in the pure world, or set an \nExpression\n in the \nEDSL\n monad.\n\n\nSeveral side-effecting instructions can simply be composed with the monadic/monoidal interface, without the need to explicitly construct an anonymous block.\n\n\nWhen we need named blocks/loops with branching instructions inside, use the \nblock\n/\nloop\n combinators which has the type \n(Label -> EDSL ()) -> EDSL ()\n. Inside the passed in continuation, we can use \nbreak'\n to perform branching. The \nLabel\n type is also opaque and cannot be inspected, the only thing we know is that it's scope-checked just like any ordinary Haskell value, so it's impossible to accidently branch to an \"inner\" label.\n\n\n\n\nThe EDSL only checks for scope safety, so we don't mess up different locals or jump to non-existent labels. Type-safety is not guaranteed (binaryen validator checks for it anyway). Underneath it's just a shallow embedded DSL implemented with a plain old state monad. Some people call it the \"remote monad design pattern\".",
            "title": "Writing WebAssembly code in Haskell"
        },
        {
            "location": "/wasm-in-hs/#writing-webassembly-code-in-haskell",
            "text": "In  Asterius.Builtins , there are WebAssembly shims which serve as our runtime. We choose to write WebAssembly code in Haskell, using Haskell as our familiar meta-language.  As of now, there are two ways of writing WebAssembly code in Haskell. The first way is directly manipulating AST types as specified in  Asterius.Types . Those types are pretty bare-metal and maps closely to binaryen IR. Simply write some code to generate an  AsteriusFunction , and ensure the function and its symbol is present in the store when linking starts. It will eventually be bundled into output WebAssembly binary file.  Directly using  Asterius.Types  is not a pleasant experience, it's basically a DDoS on one's working memory, since the developer needs to keep a lot of things in mind: parameter/local ids, block/loop labels, etc. Also, the resulting Haskell code is pretty verbose, littered with syntactic noise (e.g. tons of list concats when constructing a block)  We now provide an EDSL in  Asterius.EDSL  to construct an  AsteriusFunction . Its core type is  EDSL a , and can be composed with a  Monad  or  Monoid  interface. Most builtin functions in  Asterius.Builtins  are already refactored to use this EDSL. Typical usages:   \"Allocate\" a parameter/local. Use  param  or  local  to obtain an immutable  Expression  which corresponds to the value of a new parameter/local. There are also mutable variants.  An opaque  LVal  type is provided to uniformly deal with local reads/assignments and memory loads/stores. Once an  LVal  is instantiated, it can be used to read an  Expression  in the pure world, or set an  Expression  in the  EDSL  monad.  Several side-effecting instructions can simply be composed with the monadic/monoidal interface, without the need to explicitly construct an anonymous block.  When we need named blocks/loops with branching instructions inside, use the  block / loop  combinators which has the type  (Label -> EDSL ()) -> EDSL () . Inside the passed in continuation, we can use  break'  to perform branching. The  Label  type is also opaque and cannot be inspected, the only thing we know is that it's scope-checked just like any ordinary Haskell value, so it's impossible to accidently branch to an \"inner\" label.   The EDSL only checks for scope safety, so we don't mess up different locals or jump to non-existent labels. Type-safety is not guaranteed (binaryen validator checks for it anyway). Underneath it's just a shallow embedded DSL implemented with a plain old state monad. Some people call it the \"remote monad design pattern\".",
            "title": "Writing WebAssembly code in Haskell"
        },
        {
            "location": "/webassembly/",
            "text": "WebAssembly as a Haskell compilation target\n\n\nThere are a few issues to address when compiling Cmm to WebAssembly.\n\n\nImplementing Haskell Stack/Heap\n\n\nThe Haskell runtime maintains a TSO(Thread State Object) for each Haskell thread, and each TSO contains a separate stack for the STG machine. The WebAssembly platform has its own \"stack\" concept though; the execution of WebAssembly is based on a stack machine model, where instructions consume operands on the stack and push new values onto it.\n\n\nWe use the linear memory to simulate Haskell stack/heap. Popping/pushing the Haskell stack only involves loading/storing on the linear memory. Heap allocation only involves bumping the heap pointer. Running out of space will trigger a WebAssembly trap, instead of doing GC.\n\n\nAll discussions in the documentation use the term \"stack\" for the Haskell stack, unless explicitly stated otherwise.\n\n\nImplementing STG machine registers\n\n\nThe Haskell runtime makes use of \"virtual registers\" like Sp, Hp or R1 to implement the STG machine. The NCG(Native Code Generator) tries to map some of the virtual registers to real registers when generating assembly code. However, WebAssembly doesn't have language constructs that map to real registers, so we simply implement Cmm local registers as WebAssembly locals, and global registers as fields of \nStgRegTable\n.\n\n\nHandling control flow\n\n\nWebAssembly currently enforces structured control flow, which prohibits arbitrary branching. Also, explicit tail calls are missing.\n\n\nThe Cmm control flow mainly involves two forms of branching: in-function or cross-function. Each function consists of a map from \nhoopl\n labels to basic blocks and an entry label. Branching happens at the end of each basic block.\n\n\nIn-function branching is relatively easier to handle. \nbinaryen\n provides a \"relooper\" which can recover WebAssembly instructions with structured control flow from a control-flow graph. Note that we're using our own relooper though, see issue \n#22\n for relevant discussion.\n\n\nCross-function branching (\nCmmCall\n) is tricky. WebAssembly lacks explicit tail calls, and the relooper can't be easily used in this case since there's a computed goto, and potential targets include all Cmm blocks involved in linking. There are multiple possible ways to handle this situation:\n\n\n\n\nCollect all Cmm blocks into one function, additionally add a \"dispatcher\" block. All \nCmmCall\ns save the callee to a register and branch to the \"dispatcher\" block, and the \"dispatcher\" uses \nbr_table\n or a binary decision tree to branch to the entry block of callee.\n\n\nOne WebAssembly function for one \nCmmProc\n, and upon \nCmmCall\n the function returns the function id of callee. A mini-interpreter function at the top level repeatedly invoke the functions using \ncall_indirect\n. This approach is actually used by the unregisterised mode of \nghc\n.\n\n\n\n\nWe're using the latter approach: every \nCmmProc\n marshals to one WebAssembly function. This choice is tightly coupled with some other functionalities (e.g. debug mode) and it'll take quite some effort to switch away.\n\n\nHandling relocations\n\n\nWhen producing a WebAssembly binary, we need to map \nCLabel\ns to the precise linear memory locations for \nCmmStatics\n or the precise table ids for \nCmmProc\ns. They are unknown when compiling individual modules, so \nbinaryen\n is invoked only when linking, and during compiling we only convert \nCLabel\ns to some serializable representation.\n\n\nCurrently WebAssembly community has a \nproposal\n for linkable object format, and it's prototyped by \nlld\n. We'll probably turn to that format and use \nlld\n some day, but right now we'll simply stick to our own format for simplicity.\n\n\nThe word size story\n\n\nAlthough \nwasm64\n is scheduled, currently only \nwasm32\n is implemented. However, we are running 64-bit \nghc\n, and there are several places which need extra care:\n\n\n\n\nThe load/store instructions operate on 64-bit addresses, yet \nwasm32\n use \nuint32\n when indexing into the linear memory.\n\n\nThe \nCmmSwitch\n labels are 64-bit. \nCmmCondBranch\n also checks a 64-bit condition. \nbr_if\n/\nbr_table\n operates on \nuint32\n.\n\n\nOnly \ni32\n/\ni64\n is supported by \nwasm32\n value types, but in Cmm we also need arithmetic on 8-bit/16-bit integers.\n\n\n\n\nWe insert instructions for converting between 32/64-bits in the codegen. The \nbinaryen\n validator also helps checking bit lengths.\n\n\nAs for booleans: there's no native boolean type in either WebAssembly or Cmm. As a convention we use \nuint32\n.\n\n\nPages and addresses\n\n\nThe WebAssembly linear memory has a hard-coded page size of 64KB. There are several places which operate in units of pages rather than raw bytes:\n\n\n\n\nCurrentMemory\n/\nGrowMemory\n\n\nMemory\n component of a \nModule\n\n\n\n\nWhen performing final linking, we layout static data segments to the linear memory. We ensure the memory size is always divisable by \nMBLOCK_SIZE\n, so it's easy to allocate new mega blocks and calculate required page count.\n\n\nThe first 8 bytes of linear memory (from 0x0 to 0x7) are uninitialized. 0x0 is treated as null pointer, and loading/storing on null pointer or other uninitialized regions is prohibited. In debug mode the program immediately aborts.",
            "title": "WebAssembly as a Haskell compilation target"
        },
        {
            "location": "/webassembly/#webassembly-as-a-haskell-compilation-target",
            "text": "There are a few issues to address when compiling Cmm to WebAssembly.",
            "title": "WebAssembly as a Haskell compilation target"
        },
        {
            "location": "/webassembly/#implementing-haskell-stackheap",
            "text": "The Haskell runtime maintains a TSO(Thread State Object) for each Haskell thread, and each TSO contains a separate stack for the STG machine. The WebAssembly platform has its own \"stack\" concept though; the execution of WebAssembly is based on a stack machine model, where instructions consume operands on the stack and push new values onto it.  We use the linear memory to simulate Haskell stack/heap. Popping/pushing the Haskell stack only involves loading/storing on the linear memory. Heap allocation only involves bumping the heap pointer. Running out of space will trigger a WebAssembly trap, instead of doing GC.  All discussions in the documentation use the term \"stack\" for the Haskell stack, unless explicitly stated otherwise.",
            "title": "Implementing Haskell Stack/Heap"
        },
        {
            "location": "/webassembly/#implementing-stg-machine-registers",
            "text": "The Haskell runtime makes use of \"virtual registers\" like Sp, Hp or R1 to implement the STG machine. The NCG(Native Code Generator) tries to map some of the virtual registers to real registers when generating assembly code. However, WebAssembly doesn't have language constructs that map to real registers, so we simply implement Cmm local registers as WebAssembly locals, and global registers as fields of  StgRegTable .",
            "title": "Implementing STG machine registers"
        },
        {
            "location": "/webassembly/#handling-control-flow",
            "text": "WebAssembly currently enforces structured control flow, which prohibits arbitrary branching. Also, explicit tail calls are missing.  The Cmm control flow mainly involves two forms of branching: in-function or cross-function. Each function consists of a map from  hoopl  labels to basic blocks and an entry label. Branching happens at the end of each basic block.  In-function branching is relatively easier to handle.  binaryen  provides a \"relooper\" which can recover WebAssembly instructions with structured control flow from a control-flow graph. Note that we're using our own relooper though, see issue  #22  for relevant discussion.  Cross-function branching ( CmmCall ) is tricky. WebAssembly lacks explicit tail calls, and the relooper can't be easily used in this case since there's a computed goto, and potential targets include all Cmm blocks involved in linking. There are multiple possible ways to handle this situation:   Collect all Cmm blocks into one function, additionally add a \"dispatcher\" block. All  CmmCall s save the callee to a register and branch to the \"dispatcher\" block, and the \"dispatcher\" uses  br_table  or a binary decision tree to branch to the entry block of callee.  One WebAssembly function for one  CmmProc , and upon  CmmCall  the function returns the function id of callee. A mini-interpreter function at the top level repeatedly invoke the functions using  call_indirect . This approach is actually used by the unregisterised mode of  ghc .   We're using the latter approach: every  CmmProc  marshals to one WebAssembly function. This choice is tightly coupled with some other functionalities (e.g. debug mode) and it'll take quite some effort to switch away.",
            "title": "Handling control flow"
        },
        {
            "location": "/webassembly/#handling-relocations",
            "text": "When producing a WebAssembly binary, we need to map  CLabel s to the precise linear memory locations for  CmmStatics  or the precise table ids for  CmmProc s. They are unknown when compiling individual modules, so  binaryen  is invoked only when linking, and during compiling we only convert  CLabel s to some serializable representation.  Currently WebAssembly community has a  proposal  for linkable object format, and it's prototyped by  lld . We'll probably turn to that format and use  lld  some day, but right now we'll simply stick to our own format for simplicity.",
            "title": "Handling relocations"
        },
        {
            "location": "/webassembly/#the-word-size-story",
            "text": "Although  wasm64  is scheduled, currently only  wasm32  is implemented. However, we are running 64-bit  ghc , and there are several places which need extra care:   The load/store instructions operate on 64-bit addresses, yet  wasm32  use  uint32  when indexing into the linear memory.  The  CmmSwitch  labels are 64-bit.  CmmCondBranch  also checks a 64-bit condition.  br_if / br_table  operates on  uint32 .  Only  i32 / i64  is supported by  wasm32  value types, but in Cmm we also need arithmetic on 8-bit/16-bit integers.   We insert instructions for converting between 32/64-bits in the codegen. The  binaryen  validator also helps checking bit lengths.  As for booleans: there's no native boolean type in either WebAssembly or Cmm. As a convention we use  uint32 .",
            "title": "The word size story"
        },
        {
            "location": "/webassembly/#pages-and-addresses",
            "text": "The WebAssembly linear memory has a hard-coded page size of 64KB. There are several places which operate in units of pages rather than raw bytes:   CurrentMemory / GrowMemory  Memory  component of a  Module   When performing final linking, we layout static data segments to the linear memory. We ensure the memory size is always divisable by  MBLOCK_SIZE , so it's easy to allocate new mega blocks and calculate required page count.  The first 8 bytes of linear memory (from 0x0 to 0x7) are uninitialized. 0x0 is treated as null pointer, and loading/storing on null pointer or other uninitialized regions is prohibited. In debug mode the program immediately aborts.",
            "title": "Pages and addresses"
        },
        {
            "location": "/custom-ghc/",
            "text": "About the custom GHC fork\n\n\nAsterius currently is based on a custom GHC fork maintained \nhere\n. We regularly merge \nmaster\n commits back, build new bindists and use them on CI, to ensure our fork doesn't get bit-rotten and become painful to upstream back.\n\n\nHere is a \ncomplete\n list of differences we've made in the fork (surprisingly few at the moment):\n\n\n\n\nEnable \nD5079\n and \nD5082\n, which are kindly offered by Joachim Breitner but not all landed in \nmaster\n yet.\n\n\nImplement additional \nHooks\n: \ntcRnModuleHook\n, \nstgCmmHook\n, \ncmmToRawCmmHook\n.\n\n\n\n\nSee the \ncircle-ghc-bindist\n/\nappveyor-ghc-bindist\n branches of \nasterius\n repo for CI scripts to build bindists for the fork.",
            "title": "About the custom GHC fork"
        },
        {
            "location": "/custom-ghc/#about-the-custom-ghc-fork",
            "text": "Asterius currently is based on a custom GHC fork maintained  here . We regularly merge  master  commits back, build new bindists and use them on CI, to ensure our fork doesn't get bit-rotten and become painful to upstream back.  Here is a  complete  list of differences we've made in the fork (surprisingly few at the moment):   Enable  D5079  and  D5082 , which are kindly offered by Joachim Breitner but not all landed in  master  yet.  Implement additional  Hooks :  tcRnModuleHook ,  stgCmmHook ,  cmmToRawCmmHook .   See the  circle-ghc-bindist / appveyor-ghc-bindist  branches of  asterius  repo for CI scripts to build bindists for the fork.",
            "title": "About the custom GHC fork"
        },
        {
            "location": "/readings/",
            "text": "Reading list\n\n\nHere is a brief list of relevant readings about GHC internals and WebAssembly suited for newcomers.\n\n\n\n\nGHC documentation regarding the GHC API\n: a nice reading for anyone looking forward to using the GHC API.\n\n\nGHC commentary\n: a wiki containing lots of additional knowledge regarding GHC's implementation. Keep in mind some content is out-dated though. Some useful entries regarding this project:\n\n\nBuilding guide\n. A tl;dr for this section is our CI scripts.\n\n\nOverview of pipeline\n: we use the Hooks mechanism (specifically, \nrunPhaseHook\n) to replace the default pipeline with our own, to enable manipulation of in-memory IRs.\n\n\nHow STG works\n: a nice tutorial containing several examples of compiled examples, illustrating how the generated code works under the hood.\n\n\nThe Cmm types\n: it's outdated and the types don't exactly match the GHC codebase now, but the explanations still shed some light on how the current Cmm types work.\n\n\nThe runtime system\n: content regarding the runtime system.\n\n\n\n\n\n\nUnderstanding the Stack\n: A blog post explaining how generated code works at the assembly level. Also, its sequel \nUnderstanding the RealWorld\n\n\nThe WebAssembly spec\n: a useful reference regarding what's already present in WebAssembly.\n\n\nThe \nbinaryen\n C API\n: \nbinaryen\n handles WebAssembly code generation. There are a few differences regarding \nbinaryen\n AST and WebAssembly AST, the most notable ones:\n\n\nbinaryen\n uses a recursive \nBinaryenExpression\n which is side-effectful. The original WebAssembly standard instead uses a stack-based model and manipulates the operand stack with instructions.\n\n\nbinaryen\n contains a \"Relooper\" which can recover high-level structured control flow from a CFG. However the relooper doesn't handle jumping to unknown labels (aka computed goto), so we don't use it to handle tail calls.\n\n\n\n\n\n\n\n\nThe following entries are papers which consume much more time to read, but still quite useful for newcomers:\n\n\n\n\nMaking a fast curry: push/enter vs. eval/apply for higher-order languages\n: A thorough explanation of what is STG and how it is implemented (via two different groups of rewrite rules, also with real benchmarks)\n\n\nThe STG runtime system (revised)\n: Includes some details on the runtime system and worth a read. It's a myth why it's not merged with the commentary though. Install a TeX distribution like TeX Live or use a service like Overleaf to compile the \n.tex\n file to \n.pdf\n before reading.\n\n\nThe GHC storage manager\n: Similar to above.\n\n\nBringing the Web up to Speed with WebAssembly\n: The PLDI'17 paper about WebAssembly. Contains overview of WebAssembly design rationales and rules of small-step operational semantics.\n\n\n\n\nFinally, the GHC codebase itself is also a must-read, but since it's huge we only need to check relevant parts when unsure about its behavior. Tips on reading GHC code:\n\n\n\n\nThere are a lot of insightful and up-to-date comments which all begin with \"Notes on xxx\". It's a pity the notes are neither collected into the sphinx-generated documentation or into the haddock docs of GHC API.\n\n\nWhen writing \nbuild.mk\n for compiling GHC, add \nHADDOCK_DOCS = YES\n to ensure building haddock docs of GHC API, and \nEXTRA_HADDOCK_OPTS += --quickjump --hyperlinked-source\n to enable symbol hyperlinks in the source pages. This will save you tons of time from \ngrep\ning the ghc codebase.\n\n\ngrep\ning is still unavoidable in some cases, since there's a lot of CPP involved and they aren't well handled by haddock.",
            "title": "Reading list"
        },
        {
            "location": "/readings/#reading-list",
            "text": "Here is a brief list of relevant readings about GHC internals and WebAssembly suited for newcomers.   GHC documentation regarding the GHC API : a nice reading for anyone looking forward to using the GHC API.  GHC commentary : a wiki containing lots of additional knowledge regarding GHC's implementation. Keep in mind some content is out-dated though. Some useful entries regarding this project:  Building guide . A tl;dr for this section is our CI scripts.  Overview of pipeline : we use the Hooks mechanism (specifically,  runPhaseHook ) to replace the default pipeline with our own, to enable manipulation of in-memory IRs.  How STG works : a nice tutorial containing several examples of compiled examples, illustrating how the generated code works under the hood.  The Cmm types : it's outdated and the types don't exactly match the GHC codebase now, but the explanations still shed some light on how the current Cmm types work.  The runtime system : content regarding the runtime system.    Understanding the Stack : A blog post explaining how generated code works at the assembly level. Also, its sequel  Understanding the RealWorld  The WebAssembly spec : a useful reference regarding what's already present in WebAssembly.  The  binaryen  C API :  binaryen  handles WebAssembly code generation. There are a few differences regarding  binaryen  AST and WebAssembly AST, the most notable ones:  binaryen  uses a recursive  BinaryenExpression  which is side-effectful. The original WebAssembly standard instead uses a stack-based model and manipulates the operand stack with instructions.  binaryen  contains a \"Relooper\" which can recover high-level structured control flow from a CFG. However the relooper doesn't handle jumping to unknown labels (aka computed goto), so we don't use it to handle tail calls.     The following entries are papers which consume much more time to read, but still quite useful for newcomers:   Making a fast curry: push/enter vs. eval/apply for higher-order languages : A thorough explanation of what is STG and how it is implemented (via two different groups of rewrite rules, also with real benchmarks)  The STG runtime system (revised) : Includes some details on the runtime system and worth a read. It's a myth why it's not merged with the commentary though. Install a TeX distribution like TeX Live or use a service like Overleaf to compile the  .tex  file to  .pdf  before reading.  The GHC storage manager : Similar to above.  Bringing the Web up to Speed with WebAssembly : The PLDI'17 paper about WebAssembly. Contains overview of WebAssembly design rationales and rules of small-step operational semantics.   Finally, the GHC codebase itself is also a must-read, but since it's huge we only need to check relevant parts when unsure about its behavior. Tips on reading GHC code:   There are a lot of insightful and up-to-date comments which all begin with \"Notes on xxx\". It's a pity the notes are neither collected into the sphinx-generated documentation or into the haddock docs of GHC API.  When writing  build.mk  for compiling GHC, add  HADDOCK_DOCS = YES  to ensure building haddock docs of GHC API, and  EXTRA_HADDOCK_OPTS += --quickjump --hyperlinked-source  to enable symbol hyperlinks in the source pages. This will save you tons of time from  grep ing the ghc codebase.  grep ing is still unavoidable in some cases, since there's a lot of CPP involved and they aren't well handled by haddock.",
            "title": "Reading list"
        },
        {
            "location": "/checklist/",
            "text": "Checklist\n\n\nThis page maintains a list of upcoming tasks for the project, each task with a brief explanation, estimation of difficulty/time and connections with other tasks. Ideally this should be called \nRoadmap\n instead of \nChecklist\n, but placing accurate milestones has proven to be hard.\n\n\nTowards a TodoMVC example\n\n\nThe tasks listed in this section are all necessary ones to achieve a more \"real-world\" browser example like TodoMVC. They are currently being worked on.\n\n\nImplement \nforeign export javascript\n\n\nWe already can call JavaScript from Haskell via \nforeign import javascript\n, for JavaScript to call into Haskell, we need to implement \nforeign export javascript\n. The exported Haskell functions will be available as WebAssembly exported functions, callable in JavaScript land.\n\n\nRequirements:\n\n\n\n\nImplement \nStablePtr\n, so that Haskell closures can be safely passed between Haskell/JavaScript boundary without being garbage collected. (done, see \nstableptr\n unit test)\n\n\nImplement \nRtsAPI\n, so that JavaScript code can create Haskell closures, trigger evaluation and inspect results. (done, see \nrtsapi\n unit test)\n\n\nAdd \nStablePtr\n to JSFFI basic types. (done, see \njsffi\n unit test)\n\n\nImplement \nforeign export javascript\n syntax, add necessary logic in \nJSFFI\n/\nResolve\n (done, see \njsffi\n unit test)\n\n\n\n\nImprove \n.wasm\n/\n.js\n generation\n\n\nCurrently, given a home module, \nahc-link\n outputs a \n.wasm\n and a \n.js\n wrapper which runs in Node.js. We will need the whole thing to run in browser though.\n\n\nRequirements:\n\n\n\n\nAdd logic in \nahc-link\n to generate browser-friendly code\n\n\nMake the test suite run via a headless browser, and properly retrieve results from the browser back to Haskell\n\n\n\n\nNext important tasks\n\n\nThe following tasks are somewhat less important, but still necessary for end-user experience. They will be processed once the previous goal is accomplished.\n\n\nImprove Haskell/JavaScript marshalling\n\n\nMost JavaScript types will appear as opaque \nJSRef\n in Haskell land, but for some types that appear very often (e.g. strings and arrays), we wish they can be marshalled from/to their Haskell equivalents (e.g. lists) smoothly. Without this, even implementing a \nputStr\n will be troublesome because we must either send individual \nChar\ns to a TTY-device in JavaScript, or manually squeeze the string into a buffer in Haskell heap first.\n\n\nRequirements:\n\n\n\n\nRecognize \nString\n/\n[]\n as special JSFFI basic types, add marshalling logic from/to JavaScript strings/arrays. (in progress)\n\n\n\n\nWhen we support \naeson\n in the future, it may even be possible to marshal between \nValue\ns and JavaScript objects directly.\n\n\nSupport \nbytestring\n\n\nbytestring\n is a critical component in the Haskell ecosystem, we must support it regardless of what filthy hacks are deployed. At least non-\nInternal\n modules need to be supported.\n\n\nRequirements:\n\n\n\n\nAdd \nbytestring\n to boot libs.\n\n\nImplement \nWeak#\n, since \nByteString\n needs finalizers\n\n\nImplement WebAssembly shims in \nBuiltins\n for required C functions.\n\n\n\n\nUtilize GHC renamer/typechecker in JSFFI\n\n\nCurrently, the JSFFI thing works with parsed AST because it's less likely to mess up after rewriting. As a consequence:\n\n\n\n\nJSRef\n only works as a magic identifier. It's not in any actual Haskell module\n\n\nNo \nnewtypes\n for JSFFI basic types, since we recognize types by \nRdrName\n only\n\n\n\n\nWe need to move JSFFI processing to the phase of renamer or typechecker.\n\n\nSupport JavaScript promises in JSFFI\n\n\nThe \nforeign import javascript\n syntax currently assumes the JavaScript computation is synchronous. We need to support asynchronous JavaScript computation, by adding a \nforeign import javascript safe\n construct, and assume the JavaScript computation returns a \nPromise\n. Upon calling such a function, the scheduler saves thread state and gracefully halts the whole runtime. The runtime will be re-activated once the \nPromise\n is fulfilled.\n\n\nAdd growable heap/garbage collection to storage manager\n\n\nCurrently, the heap size is fixed and can be specified by \nahc-link --heap-size\n. By defaulting a heap size of 1GB, we pretend memory is infinite and focus work on other issues, but this can come back to bite us at any time.\n\n\nThere are two steps in this tasks:\n\n\n\n\nImplement growable heap. When GC is entered, we allocate fresh blocks and move the nursery/object pool to point to new blocks.\n\n\nImplement garbage collection. Porting all GC routines is a huge amount of work and error-prone, so we implement a non-generational one in JavaScript.\n\n\n\n\nSolve reference leaking in JSFFI\n\n\nJSRef\n is implemented much like \nStablePtr\n: a mapping from handles to objects. Whenever a \nJSRef\n enters Haskell land, the underlying object is pointed to by a mapping, but currently there's no mechanism to free a \nJSRef\n.\n\n\nSome possible fixes:\n\n\n\n\nProvide \nfreeJSRef\n in Haskell land, works for any individual \nJSRef\n\n\nProvide \nnukeJSRefs\n, can be called periodically to wipe all \nJSRef\ns\n\n\nProvide a region-based API, all \nJSRef\ns are tied to a region. Regions themselves can be allocated and recycled. Optionally there can be a global region.\n\n\n\n\nSupport 3rd-party GHC plugins\n\n\nCurrently there exist multiple plugin mechanisms in GHC:\n\n\n\n\nFrontend plugins, allowing one to create a custom major mode and execute custom login in the \nGhc\n monad when the \nghc\n process is called. GHC only does the work of parsing command line arguments.\n\n\nCore plugins, allowing one to modify the Core -> Core pipeline and insert custom passes.\n\n\nSource plugins, allowing one to inspect/modify the parsed/renamed/typechecked AST.\n\n\nHooks, allowing one to override certain GHC internal functions.\n\n\n\n\nWe should add tests to ensure 3rd-party GHC plugins work.\n\n\n\n\nFor Core plugins: we don't manipulate Core, so they should work out of the box.\n\n\nFor Source plugins: the JSFFI mechanism relies on rewriting AST (currently parsed AST), but via \nrunPhaseHook\n instead of source plugins, so this may work but needs some testing.\n\n\nFor Frontend plugins: to support a frontend plugin, work must be done on the plugin side instead of here, since the main logic is handled by plugin itself. Not practical since we use hooks to implement our modified pipeline, which is likely to be hard to integrated into another pipeline.\n\n\nFor Hooks: Not practical, reason is the same as above.\n\n\n\n\nImplement Template Haskell/GHCi\n\n\nThere are two possible ways to implement Template Haskell:\n\n\n\n\nLink with the native code produced when booting. For simple \nQ\n computations that doesn't involve \nrunIO\n this should work fine, but it won't work when one calls a WebAssembly computation in \nQ\n.\n\n\nImplement the remote interpreter for WebAssembly, much like ghcjs. When Template Haskell/GHCi is involved, we fire up a Node.js/Headless Chrome process and do all the message passing. This is the ideal solution but takes a huge amount of work.\n\n\n\n\nImplementing the first approach seems straightforward:\n\n\n\n\nWhile we compile to WebAssembly, we still perform native code generation and emit x64 object files. The emitted object files are just there to make \nCabal\n happy, but GHCi linker may take advantage of them.\n\n\nAs long as GHCi linker doesn't fail, the computation in \nQ\n monad can be executed in the \nahc\n process. It's not run in a JavaScript runtime properly, so the splice's module must not have any transitive dependency on a JSFFI import (GHCi linking will fail anyway).\n\n\n\n\nHowever, even for simple splices, the GHCi linker raises a lot of unresolved symbol errors like this:\n\n\nahc-link: /mnt/c/Users/Think/Documents/Haskell/asterius/.stack-work/install/x86_64-linux/ghc-8.7/8.7.20180920/share/x86_64-linux-ghc-8.7.20180920/asterius-0.0.1/.boot/asterius_lib/lib/x86_64-linux-ghc-8.7.20180920/base-4.12.0.0-JnKKLQIOONeDRirkEsAqF2/libHSbase-4.12.0.0-JnKKLQIOONeDRirkEsAqF2.a: unknown symbol `stg_word32ToFloatzh'\nahc-link: /mnt/c/Users/Think/Documents/Haskell/asterius/.stack-work/install/x86_64-linux/ghc-8.7/8.7.20180920/share/x86_64-linux-ghc-8.7.20180920/asterius-0.0.1/.boot/asterius_lib/lib/x86_64-linux-ghc-8.7.20180920/base-4.12.0.0-JnKKLQIOONeDRirkEsAqF2/libHSbase-4.12.0.0-JnKKLQIOONeDRirkEsAqF2.a: unknown symbol `base_GHCziFloat_zdfRealFloatDouble2_closure'\n\n\n\n\nThe ELF object files are not corrupt, but a lot of places assume the unit id of \nbase\n is simply \nbase\n, however the \nbase\n package compiled by \nahc-boot\n has a different unit id to avoid collision with the host ghc's \nbase\n.\n\n\nPatching the object files may be a valid workaround here, but I question if it's worth the effort.\n\n\nImprove \nCabal\n support\n\n\nCurrently, \nCabal\n still thinks \nahc\n is yet another \nghc\n and feeds it with \nghc\n command line arguments. We should teach it to regard \nahc\n as a new Haskell compiler, and what to do for typical commands (\nconfigure\n/\nbuild\n/\ninstall\n, etc).\n\n\nAfter \nCabal\n support is improved, we can:\n\n\n\n\nGet away with current \"boot libs\" mechanism, instead rely on regular GHC package databases\n\n\nGive users ability to build/use packages outside boot libs\n\n\nGo on with improving \ncabal-install\n, some day a plain \ncabal build --asterius\n may work\n\n\n\n\nImprove test suite\n\n\nThe current test suites have poor coverage of Haskell features.\n\n\nArchived tasks\n\n\nThe following tasks have lower priority, either due to low impact to end-user experience or significant time involved. They are archived here and may be revisited at a later date, and we're still happy to discuss or review a pull request.\n\n\nImprove WebAssembly EDSL\n\n\nWe already have a monadic EDSL for constructing WebAssembly code. There are still minor flaws with current EDSL:\n\n\n\n\nNo notion of \nstruct\ns. We manually load/store via a base pointer and an offset.\n\n\nNot type-safe. It's possible to mix-up \nI32\n/\nI64\n stuff and it's not always possible for \nbinaryen\n validator to catch the problem (especially when load/store is involved)\n\n\nGlobal/static variables need a lot of boilerplate\n\n\n\n\nSwitch away from \nbinaryen\n\n\nbinaryen\n is a fantastic library for WebAssembly code generation and has powered \nasterius\n since the beginning. However, there are reasons to switch away and implement our own WebAssembly code generation library:\n\n\n\n\nThe relooper has been a constant source of trouble. We already implement our own relooper now.\n\n\nThere's no support for linking and symbol resolution, so we have to keep two sets of types for WebAssembly: one is our own for pre-linking modules, one is the final linked data to feed to \nbinaryen\n, but they overlap a lot.\n\n\nbinaryen\n is conservative in features. We'd like to try experimental WebAssembly features (exception handling, multi-return, anyref, etc) in V8.\n\n\n\n\nIntegrate LLVM/Clang or Emscripten\n\n\nIt's a shame we can't compile simple \ncbits\n in Haskell packages and have to hand-write WebAssembly code instead.\n\n\nImplement \"Try asterius\" website\n\n\nTo increase momentum for this project, it'd be nice to have a \"try asterius\" website, where people can send snippets of modules and download compiled code to run in their browsers.\n\n\nAdd macOS support\n\n\nCurrently we don't build GHC bindists for macOS and test it on CircleCI. For the sake of macOS Haskellers this should be implemented.\n\n\nAdd Nix/Bazel support\n\n\nIt'd be nice to support building the project via Nix/Bazel.\n\n\nSupport \ninteger-gmp\n\n\nWe currently use \ninteger-simple\n, but not all packages implement the flags to switch away from \ninteger-gmp\n.\n\n\nIt's worth mentioning that V8 already has experimental support for the BigInt proposal, so \nInteger\ns should ideally be powered by \nbigint\ns under the hood.\n\n\nSupport tables-next-to-code\n\n\nOf course, we know the WebAssembly standard separates data and code, so something like tables-next-to-code won't work; but come to think of it, at link time we already know the absolute addresses of \"code\", so we can cheat a little bit here..\n\n\nIf we support both \ninteger-gmp\n and tables-next-to-code, we can stop requiring users to set up a custom GHC first, and can distribute \nasterius\n as a vanilla package.",
            "title": "Checklist"
        },
        {
            "location": "/checklist/#checklist",
            "text": "This page maintains a list of upcoming tasks for the project, each task with a brief explanation, estimation of difficulty/time and connections with other tasks. Ideally this should be called  Roadmap  instead of  Checklist , but placing accurate milestones has proven to be hard.",
            "title": "Checklist"
        },
        {
            "location": "/checklist/#towards-a-todomvc-example",
            "text": "The tasks listed in this section are all necessary ones to achieve a more \"real-world\" browser example like TodoMVC. They are currently being worked on.",
            "title": "Towards a TodoMVC example"
        },
        {
            "location": "/checklist/#implement-foreign-export-javascript",
            "text": "We already can call JavaScript from Haskell via  foreign import javascript , for JavaScript to call into Haskell, we need to implement  foreign export javascript . The exported Haskell functions will be available as WebAssembly exported functions, callable in JavaScript land.  Requirements:   Implement  StablePtr , so that Haskell closures can be safely passed between Haskell/JavaScript boundary without being garbage collected. (done, see  stableptr  unit test)  Implement  RtsAPI , so that JavaScript code can create Haskell closures, trigger evaluation and inspect results. (done, see  rtsapi  unit test)  Add  StablePtr  to JSFFI basic types. (done, see  jsffi  unit test)  Implement  foreign export javascript  syntax, add necessary logic in  JSFFI / Resolve  (done, see  jsffi  unit test)",
            "title": "Implement foreign export javascript"
        },
        {
            "location": "/checklist/#improve-wasmjs-generation",
            "text": "Currently, given a home module,  ahc-link  outputs a  .wasm  and a  .js  wrapper which runs in Node.js. We will need the whole thing to run in browser though.  Requirements:   Add logic in  ahc-link  to generate browser-friendly code  Make the test suite run via a headless browser, and properly retrieve results from the browser back to Haskell",
            "title": "Improve .wasm/.js generation"
        },
        {
            "location": "/checklist/#next-important-tasks",
            "text": "The following tasks are somewhat less important, but still necessary for end-user experience. They will be processed once the previous goal is accomplished.",
            "title": "Next important tasks"
        },
        {
            "location": "/checklist/#improve-haskelljavascript-marshalling",
            "text": "Most JavaScript types will appear as opaque  JSRef  in Haskell land, but for some types that appear very often (e.g. strings and arrays), we wish they can be marshalled from/to their Haskell equivalents (e.g. lists) smoothly. Without this, even implementing a  putStr  will be troublesome because we must either send individual  Char s to a TTY-device in JavaScript, or manually squeeze the string into a buffer in Haskell heap first.  Requirements:   Recognize  String / []  as special JSFFI basic types, add marshalling logic from/to JavaScript strings/arrays. (in progress)   When we support  aeson  in the future, it may even be possible to marshal between  Value s and JavaScript objects directly.",
            "title": "Improve Haskell/JavaScript marshalling"
        },
        {
            "location": "/checklist/#support-bytestring",
            "text": "bytestring  is a critical component in the Haskell ecosystem, we must support it regardless of what filthy hacks are deployed. At least non- Internal  modules need to be supported.  Requirements:   Add  bytestring  to boot libs.  Implement  Weak# , since  ByteString  needs finalizers  Implement WebAssembly shims in  Builtins  for required C functions.",
            "title": "Support bytestring"
        },
        {
            "location": "/checklist/#utilize-ghc-renamertypechecker-in-jsffi",
            "text": "Currently, the JSFFI thing works with parsed AST because it's less likely to mess up after rewriting. As a consequence:   JSRef  only works as a magic identifier. It's not in any actual Haskell module  No  newtypes  for JSFFI basic types, since we recognize types by  RdrName  only   We need to move JSFFI processing to the phase of renamer or typechecker.",
            "title": "Utilize GHC renamer/typechecker in JSFFI"
        },
        {
            "location": "/checklist/#support-javascript-promises-in-jsffi",
            "text": "The  foreign import javascript  syntax currently assumes the JavaScript computation is synchronous. We need to support asynchronous JavaScript computation, by adding a  foreign import javascript safe  construct, and assume the JavaScript computation returns a  Promise . Upon calling such a function, the scheduler saves thread state and gracefully halts the whole runtime. The runtime will be re-activated once the  Promise  is fulfilled.",
            "title": "Support JavaScript promises in JSFFI"
        },
        {
            "location": "/checklist/#add-growable-heapgarbage-collection-to-storage-manager",
            "text": "Currently, the heap size is fixed and can be specified by  ahc-link --heap-size . By defaulting a heap size of 1GB, we pretend memory is infinite and focus work on other issues, but this can come back to bite us at any time.  There are two steps in this tasks:   Implement growable heap. When GC is entered, we allocate fresh blocks and move the nursery/object pool to point to new blocks.  Implement garbage collection. Porting all GC routines is a huge amount of work and error-prone, so we implement a non-generational one in JavaScript.",
            "title": "Add growable heap/garbage collection to storage manager"
        },
        {
            "location": "/checklist/#solve-reference-leaking-in-jsffi",
            "text": "JSRef  is implemented much like  StablePtr : a mapping from handles to objects. Whenever a  JSRef  enters Haskell land, the underlying object is pointed to by a mapping, but currently there's no mechanism to free a  JSRef .  Some possible fixes:   Provide  freeJSRef  in Haskell land, works for any individual  JSRef  Provide  nukeJSRefs , can be called periodically to wipe all  JSRef s  Provide a region-based API, all  JSRef s are tied to a region. Regions themselves can be allocated and recycled. Optionally there can be a global region.",
            "title": "Solve reference leaking in JSFFI"
        },
        {
            "location": "/checklist/#support-3rd-party-ghc-plugins",
            "text": "Currently there exist multiple plugin mechanisms in GHC:   Frontend plugins, allowing one to create a custom major mode and execute custom login in the  Ghc  monad when the  ghc  process is called. GHC only does the work of parsing command line arguments.  Core plugins, allowing one to modify the Core -> Core pipeline and insert custom passes.  Source plugins, allowing one to inspect/modify the parsed/renamed/typechecked AST.  Hooks, allowing one to override certain GHC internal functions.   We should add tests to ensure 3rd-party GHC plugins work.   For Core plugins: we don't manipulate Core, so they should work out of the box.  For Source plugins: the JSFFI mechanism relies on rewriting AST (currently parsed AST), but via  runPhaseHook  instead of source plugins, so this may work but needs some testing.  For Frontend plugins: to support a frontend plugin, work must be done on the plugin side instead of here, since the main logic is handled by plugin itself. Not practical since we use hooks to implement our modified pipeline, which is likely to be hard to integrated into another pipeline.  For Hooks: Not practical, reason is the same as above.",
            "title": "Support 3rd-party GHC plugins"
        },
        {
            "location": "/checklist/#implement-template-haskellghci",
            "text": "There are two possible ways to implement Template Haskell:   Link with the native code produced when booting. For simple  Q  computations that doesn't involve  runIO  this should work fine, but it won't work when one calls a WebAssembly computation in  Q .  Implement the remote interpreter for WebAssembly, much like ghcjs. When Template Haskell/GHCi is involved, we fire up a Node.js/Headless Chrome process and do all the message passing. This is the ideal solution but takes a huge amount of work.   Implementing the first approach seems straightforward:   While we compile to WebAssembly, we still perform native code generation and emit x64 object files. The emitted object files are just there to make  Cabal  happy, but GHCi linker may take advantage of them.  As long as GHCi linker doesn't fail, the computation in  Q  monad can be executed in the  ahc  process. It's not run in a JavaScript runtime properly, so the splice's module must not have any transitive dependency on a JSFFI import (GHCi linking will fail anyway).   However, even for simple splices, the GHCi linker raises a lot of unresolved symbol errors like this:  ahc-link: /mnt/c/Users/Think/Documents/Haskell/asterius/.stack-work/install/x86_64-linux/ghc-8.7/8.7.20180920/share/x86_64-linux-ghc-8.7.20180920/asterius-0.0.1/.boot/asterius_lib/lib/x86_64-linux-ghc-8.7.20180920/base-4.12.0.0-JnKKLQIOONeDRirkEsAqF2/libHSbase-4.12.0.0-JnKKLQIOONeDRirkEsAqF2.a: unknown symbol `stg_word32ToFloatzh'\nahc-link: /mnt/c/Users/Think/Documents/Haskell/asterius/.stack-work/install/x86_64-linux/ghc-8.7/8.7.20180920/share/x86_64-linux-ghc-8.7.20180920/asterius-0.0.1/.boot/asterius_lib/lib/x86_64-linux-ghc-8.7.20180920/base-4.12.0.0-JnKKLQIOONeDRirkEsAqF2/libHSbase-4.12.0.0-JnKKLQIOONeDRirkEsAqF2.a: unknown symbol `base_GHCziFloat_zdfRealFloatDouble2_closure'  The ELF object files are not corrupt, but a lot of places assume the unit id of  base  is simply  base , however the  base  package compiled by  ahc-boot  has a different unit id to avoid collision with the host ghc's  base .  Patching the object files may be a valid workaround here, but I question if it's worth the effort.",
            "title": "Implement Template Haskell/GHCi"
        },
        {
            "location": "/checklist/#improve-cabal-support",
            "text": "Currently,  Cabal  still thinks  ahc  is yet another  ghc  and feeds it with  ghc  command line arguments. We should teach it to regard  ahc  as a new Haskell compiler, and what to do for typical commands ( configure / build / install , etc).  After  Cabal  support is improved, we can:   Get away with current \"boot libs\" mechanism, instead rely on regular GHC package databases  Give users ability to build/use packages outside boot libs  Go on with improving  cabal-install , some day a plain  cabal build --asterius  may work",
            "title": "Improve Cabal support"
        },
        {
            "location": "/checklist/#improve-test-suite",
            "text": "The current test suites have poor coverage of Haskell features.",
            "title": "Improve test suite"
        },
        {
            "location": "/checklist/#archived-tasks",
            "text": "The following tasks have lower priority, either due to low impact to end-user experience or significant time involved. They are archived here and may be revisited at a later date, and we're still happy to discuss or review a pull request.",
            "title": "Archived tasks"
        },
        {
            "location": "/checklist/#improve-webassembly-edsl",
            "text": "We already have a monadic EDSL for constructing WebAssembly code. There are still minor flaws with current EDSL:   No notion of  struct s. We manually load/store via a base pointer and an offset.  Not type-safe. It's possible to mix-up  I32 / I64  stuff and it's not always possible for  binaryen  validator to catch the problem (especially when load/store is involved)  Global/static variables need a lot of boilerplate",
            "title": "Improve WebAssembly EDSL"
        },
        {
            "location": "/checklist/#switch-away-from-binaryen",
            "text": "binaryen  is a fantastic library for WebAssembly code generation and has powered  asterius  since the beginning. However, there are reasons to switch away and implement our own WebAssembly code generation library:   The relooper has been a constant source of trouble. We already implement our own relooper now.  There's no support for linking and symbol resolution, so we have to keep two sets of types for WebAssembly: one is our own for pre-linking modules, one is the final linked data to feed to  binaryen , but they overlap a lot.  binaryen  is conservative in features. We'd like to try experimental WebAssembly features (exception handling, multi-return, anyref, etc) in V8.",
            "title": "Switch away from binaryen"
        },
        {
            "location": "/checklist/#integrate-llvmclang-or-emscripten",
            "text": "It's a shame we can't compile simple  cbits  in Haskell packages and have to hand-write WebAssembly code instead.",
            "title": "Integrate LLVM/Clang or Emscripten"
        },
        {
            "location": "/checklist/#implement-try-asterius-website",
            "text": "To increase momentum for this project, it'd be nice to have a \"try asterius\" website, where people can send snippets of modules and download compiled code to run in their browsers.",
            "title": "Implement \"Try asterius\" website"
        },
        {
            "location": "/checklist/#add-macos-support",
            "text": "Currently we don't build GHC bindists for macOS and test it on CircleCI. For the sake of macOS Haskellers this should be implemented.",
            "title": "Add macOS support"
        },
        {
            "location": "/checklist/#add-nixbazel-support",
            "text": "It'd be nice to support building the project via Nix/Bazel.",
            "title": "Add Nix/Bazel support"
        },
        {
            "location": "/checklist/#support-integer-gmp",
            "text": "We currently use  integer-simple , but not all packages implement the flags to switch away from  integer-gmp .  It's worth mentioning that V8 already has experimental support for the BigInt proposal, so  Integer s should ideally be powered by  bigint s under the hood.",
            "title": "Support integer-gmp"
        },
        {
            "location": "/checklist/#support-tables-next-to-code",
            "text": "Of course, we know the WebAssembly standard separates data and code, so something like tables-next-to-code won't work; but come to think of it, at link time we already know the absolute addresses of \"code\", so we can cheat a little bit here..  If we support both  integer-gmp  and tables-next-to-code, we can stop requiring users to set up a custom GHC first, and can distribute  asterius  as a vanilla package.",
            "title": "Support tables-next-to-code"
        }
    ]
}